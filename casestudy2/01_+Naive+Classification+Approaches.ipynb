{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01-+Naive+Classification+Approaches.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "67aa56f3b5665bec3fc02d1de4d7fa8e",
          "grade": false,
          "grade_id": "cell-331eb85546d2d12e",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "jCPoIQ7Je5CQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Naive Classification Approaches\n",
        "\n",
        "\n",
        "In this case study, we will build a custom classifier that takes some naive classification approaches. The approaches we'll take are:\n",
        "\n",
        "- Guessing one class at all times\n",
        "- Guessing the most common class at all times\n",
        "- Guessing randomly based on the distribution of the classes\n",
        "- Guessing randomly based on an equal chance of the classes\n",
        "\n",
        "\n",
        "We're going to build a class, `NaiveClassifier`, that can fit and predict based on the above approaches. We will then try it out on a few datasets and see what results we get. This should help you understand the minimal performance you should expect out of your machine learning models.\n",
        "\n",
        "The way `NaiveClassifier` should work is that we instantiate it with an `approach` and an optional `value` depending on the method.\n",
        "\n",
        "Examples:\n",
        "\n",
        "- always predict class 1 would be: `clf = NaiveClassifier(approach=\"always\", value=1)`\n",
        "- always predict most common class would be: `clf = NaiveClassifier(approach=\"most\")`\n",
        "- predict based on class distribution: `clf = NaiveClassifier(approach=\"distribution\")`\n",
        "- predict based on equal class distribution: `clf = NaiveClassifier(approach=\"equal\")`"
      ]
    },
    {
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "7150a9a2cf9e261ee812b05e651f385f",
          "grade": false,
          "grade_id": "cell-9213e34f09e91de2",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "QnZEUgj_e5CT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy\n",
        "from scipy import stats\n",
        "import sklearn\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "612b4a613bb8950aaa69fc8bdd1a9974",
          "grade": false,
          "grade_id": "cell-2072e6f2de42e5af",
          "locked": false,
          "schema_version": 1,
          "solution": true
        },
        "id": "IvlFw9tKe5CX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def select_most_common(labels):\n",
        "    \"\"\"Select the most common value in an iterable of labels\n",
        "    \n",
        "    Args:\n",
        "        labels (iterable): An iterable of integers representing the labels of a dataset\n",
        "    \n",
        "    Returns:\n",
        "        int: The most common element in the iterable\n",
        "    \"\"\"\n",
        "    # YOUR CODE HERE\n",
        "    counts = np.bincount(labels)\n",
        "    return np.argmax(counts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "7f10cadf9d39cca14641dae7f0c71454",
          "grade": true,
          "grade_id": "cell-8e5505cea4302a14",
          "locked": true,
          "points": 10,
          "schema_version": 1,
          "solution": false
        },
        "id": "mgworZB3e5Ca",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "assert select_most_common([1,2,2,3,4,5]) == 2\n",
        "assert select_most_common([1,1,1,1,1,1,2,2,2]) == 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "4c6c4437cc0e0f03cc51b9fcc875fd1f",
          "grade": true,
          "grade_id": "cell-4547cb50665c9747",
          "locked": false,
          "points": 20,
          "schema_version": 1,
          "solution": true
        },
        "id": "Dd2i5R6Ve5Ce",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def predict_from_distribution(distribution):\n",
        "    assert sum(distribution) == 1\n",
        "    # YOUR CODE HERE\n",
        "    c_probability = 0\n",
        "    sum_probability = []\n",
        "    for p in distribution:\n",
        "        c_probability +=p\n",
        "        sum_probability.append(c_probability)\n",
        "    r= random.uniform(0,1)\n",
        "    for index, sp in enumerate(sum_probability):\n",
        "        if r<= sp:\n",
        "          return index\n",
        "    return len(distribution)-1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "8ebc09ff2b2ab3f7a2f880ec0ceebcf1",
          "grade": false,
          "grade_id": "cell-bcf996323af296d9",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "aWcpO0j-e5Ch",
        "colab_type": "code",
        "outputId": "8abc5a4f-6dc1-4302-ee49-32a6bde0ac64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Example predictions\n",
        "# You should see 10 results with about 5 0s, 1 1, and 4 2's.\n",
        "# You can print val in order to see if it's being calculated correctly\n",
        "[predict_from_distribution([0.5, 0.1, 0.4]) for i in range(10)]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0, 2, 2, 2, 0, 0, 1, 2, 0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "d98b468ae54931df1cb7161cde8f1e4a",
          "grade": false,
          "grade_id": "cell-317516af1385c134",
          "locked": false,
          "schema_version": 1,
          "solution": true
        },
        "id": "HqCPtC7Ye5Cl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class NaiveClassifier:\n",
        "    \"\"\"A Naive Classifier that predicts classes using simple approaches.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, approach, value=None):\n",
        "        \"\"\"Initialize the NaiveClassifier\n",
        "        \n",
        "        Args:\n",
        "            approach (str): One of \"always\", \"most\", \"distribution\", \"equal\"\n",
        "            value (int, optional): Defaults to None. The value of the class to select if approach is \"always\"\n",
        "        \"\"\"\n",
        "        assert approach in [\"always\", \"most\", \"distribution\", \"equal\"]\n",
        "        self.approach = approach\n",
        "        self.value = value\n",
        "\n",
        "    def fit(self,X,y):\n",
        "        \"\"\"Fit to data and labels\n",
        "        \n",
        "        Args:\n",
        "            X (iterable): The features of the data\n",
        "            y (iterable): The labels of the data\n",
        "        \"\"\"\n",
        "        if self.approach == \"always\":\n",
        "            # YOUR CODE HERE\n",
        "            pass\n",
        "            \n",
        "        elif self.approach == \"most\":\n",
        "            # YOUR CODE HERE\n",
        "            self.most = select_most_common(y)\n",
        "            \n",
        "        elif self.approach == \"distribution\":\n",
        "            # YOUR CODE HERE\n",
        "            self.distribution = np.bincount(y)/len(y)\n",
        "            \n",
        "        elif self.approach == \"equal\":\n",
        "            # YOUR CODE HERE\n",
        "            self.equal = np.unique(y)\n",
        "            \n",
        "\n",
        "    def predict(self,X):\n",
        "        \"\"\"Predict the labels of a new set of datapoints\n",
        "        \n",
        "        Args:\n",
        "            X (iterable): The data to predict\n",
        "        \"\"\"\n",
        "        if self.approach == \"always\":\n",
        "            return [self.value]*len(X)\n",
        "            \n",
        "        elif self.approach == \"most\":\n",
        "            # YOUR CODE HERE\n",
        "            return [self.most]*len(X)\n",
        "          \n",
        "        elif self.approach == \"distribution\":\n",
        "            # YOUR CODE HERE\n",
        "            pred = np.zeros(len(X))\n",
        "            for i in range(len(X)):\n",
        "              pred[i] = predict_from_distribution(self.distribution)\n",
        "            return pred\n",
        "            \n",
        "        elif self.approach == \"equal\":\n",
        "            # YOUR CODE HERE\n",
        "            pred = np.zeros(len(X))\n",
        "            for i in range(len(X)):\n",
        "              pred[i] = random.choice(self.equal)\n",
        "            return pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "8c4619d46be0064b24af31c290541474",
          "grade": false,
          "grade_id": "cell-a22c0b698e77fade",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "LE7bGBVke5Cq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's create a few datasets that we'll use to analyze how a predictor would work with each of those approaches. Here are all the datasets we'll create:\n",
        "\n",
        "- 2 classes equally distributed\n",
        "- 2 classes with 0 at 90% and 1 at 10%\n",
        "- 3 classes equally distributed\n",
        "- 3 classes with 0 at 90%, 1 at 9% and 2 at 1%"
      ]
    },
    {
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "815c4a748b18da09e242491d772a3f70",
          "grade": false,
          "grade_id": "cell-41dd1414621c39ae",
          "locked": false,
          "schema_version": 1,
          "solution": true
        },
        "id": "fxxaav1fe5Cs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# We will create the labels for each of the listed datasets with length n\n",
        "# Create the listed datasets as binary_equal, binary_unequal, trinary_equal and trinary_unequal\n",
        "n = 15000\n",
        "features = np.zeros((n,3))\n",
        "\n",
        "# YOUR CODE HERE\n",
        "binary_equal=np.zeros((n), dtype=np.int)\n",
        "binary_unequal=np.zeros((n,), dtype=np.int)\n",
        "trinary_equal=np.zeros((n,), dtype=np.int)\n",
        "trinary_unequal=np.zeros((n,), dtype=np.int)\n",
        "\n",
        "binary_equal = [0]*7500 + [1]*7500\n",
        "binary_unequal = [0]*13500 + [1]*1500\n",
        "trinary_equal = [0]*5000 + [1]*5000 +[2]*5000\n",
        "trinary_unequal = [0]*13500 +[1]*1350 + [2]*150\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "95b318c451acafebc1ef5cf792408b8b",
          "grade": true,
          "grade_id": "cell-7458977b6dde20e7",
          "locked": true,
          "points": 10,
          "schema_version": 1,
          "solution": false
        },
        "id": "YTh-3n6Oe5DS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "assert np.all(np.bincount(binary_equal) == np.array([7500,7500]))\n",
        "assert np.all(np.bincount(binary_unequal) == np.array([13500,1500]))\n",
        "assert np.all(np.bincount(trinary_equal) == np.array([5000,5000,5000]))\n",
        "assert np.all(np.bincount(trinary_unequal) == np.array([13500,1350,150]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "1695b48d77fcea33800cc7d8d2fe39f0",
          "grade": false,
          "grade_id": "cell-900b0957df9f3734",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "XI6mdt8Ae5Da",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "datasets = [{\n",
        "    \"name\": \"Binary Classification Equally Distributed\",\n",
        "    \"labels\": binary_equal\n",
        "},{\n",
        "    \"name\": \"Binary Classification 90:10\",\n",
        "    \"labels\": binary_unequal\n",
        "},{\n",
        "    \"name\": \"3-Class Classification Equally Distributed\",\n",
        "    \"labels\": trinary_equal\n",
        "},{\n",
        "    \"name\": \"3-Class Classification 90:9:1\",\n",
        "    \"labels\": trinary_unequal\n",
        "}]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "0ae7ec3f0991ed547340d10b66be6e30",
          "grade": false,
          "grade_id": "cell-c91e34d42c72031a",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "LQeVvs9pe5Dt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Testing\n",
        "\n",
        "Let's now test out our Naive Classifiers on the above datasets. We will be training and testing on the full dataset. Since the model is actually not a machine learning algorithm and this is just for educational purposes, it will not be an issue. We are just using this approach to learn what the naive model would have predicted even on the data it trained on."
      ]
    },
    {
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "d6899b87013cac498015a59523d6f5fc",
          "grade": false,
          "grade_id": "cell-bd4beeead806b52d",
          "locked": false,
          "schema_version": 1,
          "solution": true
        },
        "id": "AGL0M4-He5Dv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create three classifers that predict always 0, 1, and 2\n",
        "# Name them always_zero, always_one and always_two respectively\n",
        "\n",
        "# YOUR CODE HERE\n",
        "    \n",
        "always_zero = NaiveClassifier(\"always\", 0)\n",
        "always_one = NaiveClassifier(\"always\", 1)\n",
        "always_two = NaiveClassifier(\"always\", 2)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "5f1007b63c813551e9e24d6519493763",
          "grade": true,
          "grade_id": "cell-522eb486ae501239",
          "locked": true,
          "points": 10,
          "schema_version": 1,
          "solution": false
        },
        "id": "442orVeze5D0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "assert always_zero.approach==\"always\"\n",
        "assert always_zero.value == 0\n",
        "assert always_one.approach==\"always\"\n",
        "assert always_one.value == 1\n",
        "assert always_two.approach==\"always\"\n",
        "assert always_two.value == 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "ca9ad85d57aa05f8982f78f82bfbb0d9",
          "grade": false,
          "grade_id": "cell-46ead0e0ddbe2d1e",
          "locked": false,
          "schema_version": 1,
          "solution": true
        },
        "id": "AwI3cowse5D3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create a classifer that predicts the most frequent class\n",
        "# Name it most_est\n",
        "\n",
        "# YOUR CODE HERE\n",
        "most_est = NaiveClassifier(\"most\",)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "de2edf8b4addac9a343f0a95ba40c188",
          "grade": true,
          "grade_id": "cell-b8897d0392ce989e",
          "locked": true,
          "points": 10,
          "schema_version": 1,
          "solution": false
        },
        "id": "3n2n-4mHe5D7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "assert most_est.approach==\"most\"\n",
        "most_est.fit([0,0,0,0,0], [0,1,1,1,0])\n",
        "assert most_est.predict([0,0,0]) == [1, 1, 1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "a89a20e3857151da03a35a707efaa20a",
          "grade": false,
          "grade_id": "cell-6dd3561533dc7fab",
          "locked": false,
          "schema_version": 1,
          "solution": true
        },
        "id": "bfkCwOuoe5D_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create a classifer that predicts based on the distribution of the classes\n",
        "# Name it dist_est\n",
        "\n",
        "# YOUR CODE HERE\n",
        "dist_est = NaiveClassifier(\"distribution\",)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "1cb1c2331e7dcbd7abf86935da4cef23",
          "grade": true,
          "grade_id": "cell-333373b5985f80a3",
          "locked": true,
          "points": 10,
          "schema_version": 1,
          "solution": false
        },
        "id": "A5DZGSW5e5EE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "assert dist_est.approach == \"distribution\"\n",
        "dist_est.fit([0,0,0,0,0], [0,0,1,1,1])\n",
        "random.seed(0)\n",
        "assert sum(dist_est.predict([0,0,0,0,0])) == 4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "bd5dbac962f0f4ca653eb8e8c80057a9",
          "grade": false,
          "grade_id": "cell-b60f6f134886db8f",
          "locked": false,
          "schema_version": 1,
          "solution": true
        },
        "id": "box4lIyce5EG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create a classifer that predicts equally any of the classes\n",
        "# Name it equal_est\n",
        "\n",
        "# YOUR CODE HERE\n",
        "equal_est = NaiveClassifier(\"equal\",4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "087b190e1eb7e16e6af8ec00dc2b73a4",
          "grade": true,
          "grade_id": "cell-a6244fa35c54a4b6",
          "locked": true,
          "points": 10,
          "schema_version": 1,
          "solution": false
        },
        "id": "sSS-upc4e5EJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "assert equal_est.approach == \"equal\"\n",
        "equal_est.fit([0,0,0,0,0], [0,1,1,1,1])\n",
        "random.seed(0)\n",
        "assert sum(equal_est.predict([0,0,0,0])) == 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eOKbv6ske5EL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "estimators = [\n",
        "    {\n",
        "        \"name\": \"Always Zero\",\n",
        "        \"estimator\": always_zero\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Always One\",\n",
        "        \"estimator\": always_one\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Always Two\",\n",
        "        \"estimator\": always_two\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Most Common\",\n",
        "        \"estimator\": most_est\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Distribution Based\",\n",
        "        \"estimator\": dist_est\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Equally\",\n",
        "        \"estimator\": equal_est\n",
        "    }\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "40fc223fad2f83f71f1e6fb1e9083339",
          "grade": true,
          "grade_id": "cell-4fa0002da84133fb",
          "locked": false,
          "points": 70,
          "schema_version": 1,
          "solution": true
        },
        "id": "f_vW8A2ze5ET",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5782
        },
        "outputId": "7a269466-5e01-439e-f077-17ca0a6c6d87"
      },
      "cell_type": "code",
      "source": [
        "# For each dataset, apply each estimator and save the predictions as pred\n",
        "for dataset in datasets:\n",
        "    name = dataset[\"name\"]\n",
        "    labels = dataset[\"labels\"]\n",
        "    print(\"=\"*20)\n",
        "    print(f\"{name}\")\n",
        "    print(\"=\"*20)\n",
        "    for est in estimators:\n",
        "        estimator_name = est[\"name\"]\n",
        "        print(\"-\"*20)\n",
        "        print(f\"Estimating with {estimator_name}\")\n",
        "        print(\"-\"*20)\n",
        "        # YOUR CODE HERE\n",
        "        #print(estimators)\n",
        "        #print(dataset)\n",
        "        pred = []\n",
        "        estimator = est[\"estimator\"]\n",
        "        pred = estimator.predict(features)\n",
        "        \n",
        "        print(f\"Produced an accuracy score of {accuracy_score(labels, pred)} and the following report\")\n",
        "        print(classification_report(labels, pred))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "====================\n",
            "Binary Classification Equally Distributed\n",
            "====================\n",
            "--------------------\n",
            "Estimating with Always Zero\n",
            "--------------------\n",
            "Produced an accuracy score of 0.5 and the following report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67      7500\n",
            "           1       0.00      0.00      0.00      7500\n",
            "\n",
            "   micro avg       0.50      0.50      0.50     15000\n",
            "   macro avg       0.25      0.50      0.33     15000\n",
            "weighted avg       0.25      0.50      0.33     15000\n",
            "\n",
            "--------------------\n",
            "Estimating with Always One\n",
            "--------------------\n",
            "Produced an accuracy score of 0.5 and the following report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      7500\n",
            "           1       0.50      1.00      0.67      7500\n",
            "\n",
            "   micro avg       0.50      0.50      0.50     15000\n",
            "   macro avg       0.25      0.50      0.33     15000\n",
            "weighted avg       0.25      0.50      0.33     15000\n",
            "\n",
            "--------------------\n",
            "Estimating with Always Two\n",
            "--------------------\n",
            "Produced an accuracy score of 0.0 and the following report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      7500\n",
            "           1       0.00      0.00      0.00      7500\n",
            "           2       0.00      0.00      0.00         0\n",
            "\n",
            "   micro avg       0.00      0.00      0.00     15000\n",
            "   macro avg       0.00      0.00      0.00     15000\n",
            "weighted avg       0.00      0.00      0.00     15000\n",
            "\n",
            "--------------------\n",
            "Estimating with Most Common\n",
            "--------------------\n",
            "Produced an accuracy score of 0.5 and the following report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      7500\n",
            "           1       0.50      1.00      0.67      7500\n",
            "\n",
            "   micro avg       0.50      0.50      0.50     15000\n",
            "   macro avg       0.25      0.50      0.33     15000\n",
            "weighted avg       0.25      0.50      0.33     15000\n",
            "\n",
            "--------------------\n",
            "Estimating with Distribution Based\n",
            "--------------------\n",
            "Produced an accuracy score of 0.5074 and the following report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.41      0.46      7500\n",
            "           1       0.51      0.60      0.55      7500\n",
            "\n",
            "   micro avg       0.51      0.51      0.51     15000\n",
            "   macro avg       0.51      0.51      0.50     15000\n",
            "weighted avg       0.51      0.51      0.50     15000\n",
            "\n",
            "--------------------\n",
            "Estimating with Equally\n",
            "--------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
            "  'recall', 'true', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Produced an accuracy score of 0.5061333333333333 and the following report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.51      0.51      7500\n",
            "           1       0.51      0.51      0.51      7500\n",
            "\n",
            "   micro avg       0.51      0.51      0.51     15000\n",
            "   macro avg       0.51      0.51      0.51     15000\n",
            "weighted avg       0.51      0.51      0.51     15000\n",
            "\n",
            "====================\n",
            "Binary Classification 90:10\n",
            "====================\n",
            "--------------------\n",
            "Estimating with Always Zero\n",
            "--------------------\n",
            "Produced an accuracy score of 0.9 and the following report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      1.00      0.95     13500\n",
            "           1       0.00      0.00      0.00      1500\n",
            "\n",
            "   micro avg       0.90      0.90      0.90     15000\n",
            "   macro avg       0.45      0.50      0.47     15000\n",
            "weighted avg       0.81      0.90      0.85     15000\n",
            "\n",
            "--------------------\n",
            "Estimating with Always One\n",
            "--------------------\n",
            "Produced an accuracy score of 0.1 and the following report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00     13500\n",
            "           1       0.10      1.00      0.18      1500\n",
            "\n",
            "   micro avg       0.10      0.10      0.10     15000\n",
            "   macro avg       0.05      0.50      0.09     15000\n",
            "weighted avg       0.01      0.10      0.02     15000\n",
            "\n",
            "--------------------\n",
            "Estimating with Always Two\n",
            "--------------------\n",
            "Produced an accuracy score of 0.0 and the following report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00     13500\n",
            "           1       0.00      0.00      0.00      1500\n",
            "           2       0.00      0.00      0.00         0\n",
            "\n",
            "   micro avg       0.00      0.00      0.00     15000\n",
            "   macro avg       0.00      0.00      0.00     15000\n",
            "weighted avg       0.00      0.00      0.00     15000\n",
            "\n",
            "--------------------\n",
            "Estimating with Most Common\n",
            "--------------------\n",
            "Produced an accuracy score of 0.1 and the following report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00     13500\n",
            "           1       0.10      1.00      0.18      1500\n",
            "\n",
            "   micro avg       0.10      0.10      0.10     15000\n",
            "   macro avg       0.05      0.50      0.09     15000\n",
            "weighted avg       0.01      0.10      0.02     15000\n",
            "\n",
            "--------------------\n",
            "Estimating with Distribution Based\n",
            "--------------------\n",
            "Produced an accuracy score of 0.4288 and the following report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.41      0.56     13500\n",
            "           1       0.10      0.62      0.18      1500\n",
            "\n",
            "   micro avg       0.43      0.43      0.43     15000\n",
            "   macro avg       0.51      0.51      0.37     15000\n",
            "weighted avg       0.83      0.43      0.52     15000\n",
            "\n",
            "--------------------\n",
            "Estimating with Equally\n",
            "--------------------\n",
            "Produced an accuracy score of 0.4992666666666667 and the following report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.50      0.64     13500\n",
            "           1       0.10      0.50      0.17      1500\n",
            "\n",
            "   micro avg       0.50      0.50      0.50     15000\n",
            "   macro avg       0.50      0.50      0.40     15000\n",
            "weighted avg       0.82      0.50      0.59     15000\n",
            "\n",
            "====================\n",
            "3-Class Classification Equally Distributed\n",
            "====================\n",
            "--------------------\n",
            "Estimating with Always Zero\n",
            "--------------------\n",
            "Produced an accuracy score of 0.3333333333333333 and the following report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.33      1.00      0.50      5000\n",
            "           1       0.00      0.00      0.00      5000\n",
            "           2       0.00      0.00      0.00      5000\n",
            "\n",
            "   micro avg       0.33      0.33      0.33     15000\n",
            "   macro avg       0.11      0.33      0.17     15000\n",
            "weighted avg       0.11      0.33      0.17     15000\n",
            "\n",
            "--------------------\n",
            "Estimating with Always One\n",
            "--------------------\n",
            "Produced an accuracy score of 0.3333333333333333 and the following report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      5000\n",
            "           1       0.33      1.00      0.50      5000\n",
            "           2       0.00      0.00      0.00      5000\n",
            "\n",
            "   micro avg       0.33      0.33      0.33     15000\n",
            "   macro avg       0.11      0.33      0.17     15000\n",
            "weighted avg       0.11      0.33      0.17     15000\n",
            "\n",
            "--------------------\n",
            "Estimating with Always Two\n",
            "--------------------\n",
            "Produced an accuracy score of 0.3333333333333333 and the following report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      5000\n",
            "           1       0.00      0.00      0.00      5000\n",
            "           2       0.33      1.00      0.50      5000\n",
            "\n",
            "   micro avg       0.33      0.33      0.33     15000\n",
            "   macro avg       0.11      0.33      0.17     15000\n",
            "weighted avg       0.11      0.33      0.17     15000\n",
            "\n",
            "--------------------\n",
            "Estimating with Most Common\n",
            "--------------------\n",
            "Produced an accuracy score of 0.3333333333333333 and the following report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      5000\n",
            "           1       0.33      1.00      0.50      5000\n",
            "           2       0.00      0.00      0.00      5000\n",
            "\n",
            "   micro avg       0.33      0.33      0.33     15000\n",
            "   macro avg       0.11      0.33      0.17     15000\n",
            "weighted avg       0.11      0.33      0.17     15000\n",
            "\n",
            "--------------------\n",
            "Estimating with Distribution Based\n",
            "--------------------\n",
            "Produced an accuracy score of 0.32953333333333334 and the following report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.33      0.40      0.36      5000\n",
            "           1       0.33      0.59      0.42      5000\n",
            "           2       0.00      0.00      0.00      5000\n",
            "\n",
            "   micro avg       0.33      0.33      0.33     15000\n",
            "   macro avg       0.22      0.33      0.26     15000\n",
            "weighted avg       0.22      0.33      0.26     15000\n",
            "\n",
            "--------------------\n",
            "Estimating with Equally\n",
            "--------------------\n",
            "Produced an accuracy score of 0.33393333333333336 and the following report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.33      0.50      0.40      5000\n",
            "           1       0.33      0.50      0.40      5000\n",
            "           2       0.00      0.00      0.00      5000\n",
            "\n",
            "   micro avg       0.33      0.33      0.33     15000\n",
            "   macro avg       0.22      0.33      0.27     15000\n",
            "weighted avg       0.22      0.33      0.27     15000\n",
            "\n",
            "====================\n",
            "3-Class Classification 90:9:1\n",
            "====================\n",
            "--------------------\n",
            "Estimating with Always Zero\n",
            "--------------------\n",
            "Produced an accuracy score of 0.9 and the following report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      1.00      0.95     13500\n",
            "           1       0.00      0.00      0.00      1350\n",
            "           2       0.00      0.00      0.00       150\n",
            "\n",
            "   micro avg       0.90      0.90      0.90     15000\n",
            "   macro avg       0.30      0.33      0.32     15000\n",
            "weighted avg       0.81      0.90      0.85     15000\n",
            "\n",
            "--------------------\n",
            "Estimating with Always One\n",
            "--------------------\n",
            "Produced an accuracy score of 0.09 and the following report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00     13500\n",
            "           1       0.09      1.00      0.17      1350\n",
            "           2       0.00      0.00      0.00       150\n",
            "\n",
            "   micro avg       0.09      0.09      0.09     15000\n",
            "   macro avg       0.03      0.33      0.06     15000\n",
            "weighted avg       0.01      0.09      0.01     15000\n",
            "\n",
            "--------------------\n",
            "Estimating with Always Two\n",
            "--------------------\n",
            "Produced an accuracy score of 0.01 and the following report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00     13500\n",
            "           1       0.00      0.00      0.00      1350\n",
            "           2       0.01      1.00      0.02       150\n",
            "\n",
            "   micro avg       0.01      0.01      0.01     15000\n",
            "   macro avg       0.00      0.33      0.01     15000\n",
            "weighted avg       0.00      0.01      0.00     15000\n",
            "\n",
            "--------------------\n",
            "Estimating with Most Common\n",
            "--------------------\n",
            "Produced an accuracy score of 0.09 and the following report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00     13500\n",
            "           1       0.09      1.00      0.17      1350\n",
            "           2       0.00      0.00      0.00       150\n",
            "\n",
            "   micro avg       0.09      0.09      0.09     15000\n",
            "   macro avg       0.03      0.33      0.06     15000\n",
            "weighted avg       0.01      0.09      0.01     15000\n",
            "\n",
            "--------------------\n",
            "Estimating with Distribution Based\n",
            "--------------------\n",
            "Produced an accuracy score of 0.4144 and the following report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.40      0.55     13500\n",
            "           1       0.09      0.59      0.15      1350\n",
            "           2       0.00      0.00      0.00       150\n",
            "\n",
            "   micro avg       0.41      0.41      0.41     15000\n",
            "   macro avg       0.33      0.33      0.24     15000\n",
            "weighted avg       0.82      0.41      0.51     15000\n",
            "\n",
            "--------------------\n",
            "Estimating with Equally\n",
            "--------------------\n",
            "Produced an accuracy score of 0.4968 and the following report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.50      0.64     13500\n",
            "           1       0.09      0.51      0.16      1350\n",
            "           2       0.00      0.00      0.00       150\n",
            "\n",
            "   micro avg       0.50      0.50      0.50     15000\n",
            "   macro avg       0.33      0.34      0.27     15000\n",
            "weighted avg       0.82      0.50      0.59     15000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "389cdf459cce5380870da35116edc90b",
          "grade": true,
          "grade_id": "cell-9b05ea606e1c0cd8",
          "locked": false,
          "points": 80,
          "schema_version": 1,
          "solution": true
        },
        "id": "w_BJ6mz9e5Eb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "62491093-a024-4f2c-950e-bd66909727a7"
      },
      "cell_type": "code",
      "source": [
        "# Please describe your conclusions based on the above results\n",
        "# You must write at least 300 characters\n",
        "# This portion is worth 100 points (20% of CS)\n",
        "# Save your answer to conclusions\n",
        "\n",
        "# YOUR CODE HERE\n",
        "conclusions = \"From this case study 2 part 1, we realized that accuracy number is not represented correctly. For example, even though the accuracy score is higher in some methods, this does not mean that the accuracy will remain high if other datasets are used. In a sense, a particular dataset may be biased towards the specific estimator method. Common problem in statistic, an estimator method is biased if it favors some specific outcome. A sample of dataset is also biased if certain groups are underrepresented or overrepresented relative to the norm. Recognizing the impact of biased and unbiased dataset into an algorithm is an important portion in the overall statistics of machine learning.\"\n",
        "print(conclusions)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "From this case study 2 part 1, we realized that accuracy number is not represented correctly. For example, even though the accuracy score is higher in some methods, this does not mean that the accuracy will remain high if other datasets are used. In a sense, a particular dataset may be biased towards the specific estimator method. Common problem in statistic, an estimator method is biased if it favors some specific outcome. A sample of dataset is also biased if certain groups are underrepresented or overrepresented relative to the norm. Recognizing the impact of biased and unbiased dataset into an algorithm is an important portion in the overall statistics of machine learning.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "f96902f6df775132e627f13cb16c2783",
          "grade": true,
          "grade_id": "cell-355d52c0428b75f3",
          "locked": true,
          "points": 20,
          "schema_version": 1,
          "solution": false
        },
        "id": "C6aNPOO7e5Ef",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "assert len(conclusions) > 300"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "35c02446ada971330235203f8d3b177f",
          "grade": false,
          "grade_id": "cell-d45e75d8071c765c",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "YSHZ3nl1e5Em",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Feedback"
      ]
    },
    {
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "cc89e0660ccb53529a249ada6cc1a0cd",
          "grade": false,
          "grade_id": "cell-fb93624c53422815",
          "locked": false,
          "schema_version": 1,
          "solution": true
        },
        "id": "GKmQSG--e5En",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def feedback():\n",
        "    \"\"\"Provide feedback on the contents of this exercise\n",
        "    \n",
        "    Returns:\n",
        "        string\n",
        "    \"\"\"\n",
        "    # YOUR CODE HERE\n",
        "    raise NotImplementedError()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "51c4d2a5734ab18322474a6f62fb5382",
          "grade": true,
          "grade_id": "cell-10ee4b2b9ba4be3d",
          "locked": true,
          "points": 0,
          "schema_version": 1,
          "solution": false
        },
        "id": "uMPvI7QIe5Ep",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}